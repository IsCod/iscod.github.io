## golang

### 值类型&引用类型传递

引用类型传递: `map`, `slice`, `interface`, `chan`, `pointer`

值类型传递: `array`, `struct` ,`int`, `float`, `bool`, `string`

*make可以创建哪些*

```go
var ch, sl, ma = make(chan int), make([]int, 0), make(map[int]int)
```

* make, new 的区别

1. make 只能创建三种类型，new 可以创建任意类型
2. make返回的是Type对象，new 返回的是Type指针

### 控制并发控制的三种模式

1. 通过`chan`进行控制
1. 通过`Waitgroup`进行控制
1. 通过`Context`上下文进行控制

### chan

* chan应用到哪些场景?

1. 协程见的通信
1. 控制并发数
1. 定时任务 time.after

* chan可以传入nil吗？

当chan定义为引用类型时，可以传入nil, 非引用类型如`int`、`string`、`array`, `struct`不行


### RPC

gRPC是golang实现的RPC框架

RPC是一种远程服务调用方案，RPC负责底层的通信协议和序列化方式。服务调用者可以想调用本地函数一样调用远程服务。
gRPC对接口与严格的约束，安全性高，且更适合高并发场景。
gRPC有明确的接口规范，
RCP效率更高，RPC使用自定义的TCP协议，可以让请求报文体积更小，提高传输效率

rest，是网络中的clinet和server的交互形式

### 读写锁

golang的`sync`包提供了 互斥锁`sync.Mutex`和读写锁`sync.RWMutex`两种锁

`sync.Mutex`互斥锁，既不可同时运行。互斥锁有两个方法`Lock`和`Unlock`。通常在加锁有采用`defer`语句解锁。

`sync.RWMutex`读写锁，可以理解为`多读单写锁`。`读`是运行同时运行的，`写`是互斥的。一般有四种情况

读锁之间不互斥，没有写锁的情况下，读锁是无阻塞的，多个协程可以同时获得读锁。
写锁之间是互斥的，存在写锁，其他写锁阻塞。
写锁与读锁是互斥的，如果存在读锁，写锁阻塞，如果存在写锁，读锁阻塞。


sync.map是golang官方包实现的并发安全的map结构

### 协程和线程和进程的区别

* 进程

进程是系统资源分配和调度的最小单位，每个进程有自己的内存空间，不同进程之前通讯是通过进程通讯来完成

* 线程

线程是进程的一个实体，他是比进程更小的能独立运行的基本单位。线程间通讯最要通过共享内存，资源开销较小

* 协程

协程是一种用户态的轻量级线程，协程的调度是通过用户来进行控制的。协程拥有自己的寄存器上下文和栈（P）


线程是进程的一个实体

### GMP

* G: goroutine 调度实体, 既用户代码,   # 在本地队列中不断切换执行
* M: machine 内核线程, 既系统线程, 负责代码执行
* P: processor 逻辑处理器, 保存了调度上下文。也可以理解为局部的一个调度器。P的数量由`runtime.GOMAXPROCS`控制,

每个p都有一个runqueue队列。p负责goroutine调度到`M线程`上运行。

除此之外呢，golang还维护一个全局的runqueue队列。


当某个p的本地runqueue队列运行完。首先 `p`就会从全局队列当中获取新的`goroutine`.

如果全局队列没有`goroutine`.

那么会从其它的`P`本地队列中偷一些`goroutine`(一半)


当某一个进程`M0`被阻塞时，P会找到一个新的`M1`进程上进行运行。
当被阻塞的`M0`返回`syscall`(既可以运行不阻塞了) `M0`会尝试获取一个`P`来继续运行。如果没有获取`P`，那么会将`MO`阻塞的`G`放入全局`runqueue`

### csp

CSP 模型是*以通信的方式来共享内存*，不同于传统的多线程通过共享内存来通信。

主要用于描述两个独立的并发实体, 通过共享的通讯 channel (管道)进行通信的并发模型。


### 如何退出`goroutine`

`goroutine`的退出一般有两种模式： 1.超时模式 2.关闭chan

超时模式是使用`time.After`启动了一个异步的定时器，返回一个 channel，当超过指定的时间后，该 channel 将会接受到信号

2，通过一个chan的关闭通知，进行`goroutine`的关闭

### 什么情况下死锁，如何避免？

单个`goroutine`自读自写一个没有缓冲能力的`chan`

range `chan`时要注意关闭，如果不关闭一直阻塞


### 垃圾回收

#### 垃圾回收的三种算法

1. 引用计数

每个对象维护一个引用计数, 当被引用对象被创建或被赋值给其他对象时引用计数自动加 +1；如果这个对象被销毁，则计数 -1 ，当计数为 0 时，回收该对象。 [redis内存回收](https://iscod.github.io/#/nosql/redis?id=%e5%86%85%e5%ad%98%e5%9b%9e%e6%94%b6)

redis就是采用的该种方法
2. 标记清除, 从根变量开始遍历所有引用的对象，引用的对象标记“被引用”，没有被标记的则进行回收
3. 分代收集

golang的垃圾回收是通过`GC`来实现的。

GC采用的理念是`三色标记`. `三色标记`可以理解成将一个内存标记为三种状态

1，白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收
2，黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象 以及从根对象可达的对象
3，灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象

垃圾回收的可以理解为三个步骤

1. 从灰色对象的集合中选择一个灰色对象并将其标记成黑色；
2. 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收；
3. 重复上述两个步骤直到不存在灰色对象；

当三色的标记清除的标记阶段结束之后，应用程序的堆中就不存在任何的灰色对象，我们只能看到黑色的存活对象以及白色的垃圾对象，垃圾收集器可以回收这些白色的垃圾

##### 垃圾回收演进

* V1.0 版本完全串行的标记和清除，会暂停整个程序`STW`
* V1.5 引入三色标记清扫的并发处理
* V1.8 使用混合屏障(插入和删除屏障)
* V1.9 彻底移除暂停整个程序的重新扫描栈过程

### 反射

反射是通过`reflect`(ruifulekede)包来实现。它可以让程序操作不同类型的对象
`reflect`包提供了两个重要的接口`reflect.TypeOf` 和 `reflect.ValueOf`。TypeOf用来获取类型信息。ValueOf用来获取数据

实现了运行时的反射能力，能够让程序操作不同类型的对象1。反射包中有两对非常重要的函数和类型，reflect.TypeOf 能获取类型信息，reflect.ValueOf 能获取数据的运行时表示

```
type User struct {
Name string
Age  int
}

func main() {
u := User{Name: "ning", Age: 12}
tp := reflect.TypeOf(u)
va := reflect.ValueOf(u)
for i := 0; i < tp.NumField(); i++ {
fmt.Println(tp.Field(i).Name, "：", va.FieldByName(tp.Field(i).Name))
}
}

```


### 高并发场景

高并发是一个系统工程主要是通过四个方面来着优化

1. 业务层面
1. 可以通过流程设计减少热点数据的访问量，比如做预约,增加实名认证等条件才可参加活动
1. 比如可以增加访问验证码等步骤，延迟用户核心数据访问频率，同时可以放置抢购脚本

1. 服务器硬件设施方面
1. 系统分离，可以尝试将高并发场景单独做成一个server服务，单独部署减少对其他系统的影响。并且可以专门做相应的优化，比如请求较高可以做动态的伸缩服务器硬件。也可以进行相应的流量均衡
1. 可以做一些静态资源的缓存CDN。减少对核心服务器的访问。

1. 代码逻辑层面
1. 尽可能的减少数据操作（读写数据库）。
1. 可以采用消息队列做中间层，将并发的访问转换为顺序的请求访问
1. golang的本身支持高并发，可以结合`goroutine`进行逻辑的并发处理
1. 数据库端
1. 读取数据进行Cache缓存。可以使用Memcache、redis进行数据的提前缓存。同时要注意缓存的命中率问题。
在数据更新时，尽可能的及时刷新缓存，保证命中率
1. 可以采用redis结合lua脚本保证数据的一致性
1. 可以采用数据库事务来进行原子性操作
1. 另外可以在应用程序层面, 通过操作后再次查询结果的方式，保证执行的结果
高并发的原则是在保证数据一致性的前提下尽可能的提高响应速度，保证可用性

## redis

### redis有哪些特性/redis为什么快？

1. 纯内存的数据访问
1. 单线程避免上下文切换（io是多路复用，命令还是单线程）
1. `渐进式Rehash`, 缓存系统时间戳

### redis适用哪些场景？

1. 缓存
1. 分布式SESSION
1. 计数器
1. 分布式锁
1. 排行榜
1. 消息队列

### redis有哪些高级功能？

1. lua
1. Pipeline
1. 事务（MULTI）
1. 慢日志

```bash
# 设置多少时间的日志记录到慢日志（1000µs）
127.0.0.1:6380> CONFIG SET slowlog-log-slower-than 1000
```

### redis如何实现分布式锁/redis实现分布式锁需要注意哪些？

1. 死锁(setnx)
1. 锁有效期的续期(witch dog)
1. 锁的释放(根据钥匙进行释放)

### redis如何实现消息队列/redis实现消息队列需要注意哪些？

1. 基于List的`LPUSH`+`BRPOP`实现

优点是足够简单，消费消息延迟几乎为0，但是要处理闲置连接问题。

当没有消息时，线程会阻塞，`BRPOP`客户端闲置，闲置太久，服务器一般会主动断开连接，减少闲置资源占用，这个时候brpop和blpop会抛出异常，所以在编写客户端消费时，要做好异常捕获，然后进行重试。

```
# 生产者发送消息
127.0.0.1:6382> LPUSH lmq1 mess1 mess2 mess3
# 消费者，BRPOP需要提供一个timeout时间,这里是 10s，当没有消息时，会超时断开
127.0.0.1:6382> BRPOP lm1 10
1) "lm1"
2) "mess1"
```

1. sorted-set实现

1. PUB/SUB，订阅发布

优点：

典型的广播模式，一个消息可以发布到多个消费者，多信道订阅，消费者可以同时订阅多个信道，从而接受多类消息，消息即使发送，消息不回等待消费者去读取，消费者会自动接收到信道发布的消息

缺点：

消息一旦发布，如果消费者不在线，这消息丢失，不能寻回。不能保证每个消费者接受到的时间是一致的。同时若消费者客户端消息积压到一定程度，会被强制断开，导致消息丢失。

可见该模式不适合做消息存储，消息积压类的业务。适合处理广播，即时通讯和即时反馈的业务

```bash
127.0.0.1:6382> PUBLISH chan1 mess1
# 客户端订阅两个信道
127.0.0.1:6382> SUBSCRIBE chan1 chan2
```

1. Stream

`Stream`是Redis 5.0版本引入的一个新的数据类型。它提供了一组允许消费者以阻塞的方式等待生产者向`Stream`发送消息。此外它还提供了消费组的概念。注意它并未提供像`kafka`中分区的概念

```bash
# 生产者添加消息
127.0.0.1:6383> XADD mystream * filed1 val1 filed2 val2
# 读取10条消息
127.0.0.1:6383> XREAD count 10 STREAMS mystream 0
# 读取所有消息
127.0.0.1:6383> XREAD count 10 STREAMS mystream 0
# 添加消息组
127.0.0.1:6383> XGROUP CREATE mystream mgroup1 $
# 消息组读取消息
127.0.0.1:6383> XREADGROUP GROUP mgroup1 consumer1 count 2 STREAMS mystream >
```

* Stream 消息太多怎么办？

如果Stream中消息累计太多，Stream链表就变长，内存有可能超出，而`XDEL`只是给消息做了标识，并未删除数据。那如何控制？

`XADD`指令提供了一个定长长度`maxlen`, 可以确保消息超过指定长度时，删除老的消息。因此可能会出现消息丢失

* 消息如果忘记`ACK`会怎样/ 为什么要及时进行`ACK`?

Stream在消息结构中保存了正在处理中的id列表（PEL），如果消费者收到消息处理完而没有回复`ACK`,那么就会导致`PEL`表不断增长，如果消费组很多，那么`PEL`就会占用很多内存。所以消息要及时进行`ACK`


* 死信消息如何处理？

某个消息不能被消费者处理，也就是不能被`XACK`,长时间处于`Pending`列表中，即使被反复的转移至其他消费者也不能被处理，该类消息的`delivery count`（XPENDING 可以查询该次数）就会不断累加，当累加我们预设的累加值时，我们就认为是坏消息。

`XDEL` + `XACK`进行删除

### 如何提高缓存的命中率？

1. 数据预加载（数据提前加载到redis）
1. 增加缓存的存储空间，提高缓存数据量
1. 调整缓存类型，提高业务缓存利用率
1. 提升缓存的刷新频次，（可以通过bin log/mq 及时通知到缓存服务，进行数据更新）

### 如何保证缓存与数据库双写时的一致性？

只要是使用了缓存与数据库两种数据源，就一定会存在数据同步的问题

数据更新时缓存更新的四种策略：

1. 先更新缓存后更新DB(一般不考虑，如果DB出错导致数据不一致)
2. 先更新DB后更新缓存(一般不考虑，如果缓存更新失败导致数据不一致)
3. 删除缓存后更新DB

这种策略也会出现一下问题：

A请求先删除了缓存，还未及时更新数据库。而此时B进行了查询, 将老数据更新到了缓存, 就造成数据不一致。
该问题一般可采用`延迟双删`解决，延迟双删策略是：

1. 先删除缓存
2. 更新数据库
3. 休眠1s后，再次删除缓存

这样可以将1s内的缓存脏数据进行删除，休眠时间可以根据自己的业务平均耗时进行评估一般在几百毫秒

4. 先更新DB后删除缓存（一般情况选择该种类）

这种策略保证只有在查询速度比删除缓存慢的情况下才会出现数据不一致的情况，而这种情况来说相对少很多。
而且可以结合采用延时删除进一步保证数据的一致性。

### redis的持久化有哪些方式和区别？

1. rdb
1. aof
1. reb+aof

aof记录命令，rdb备份数据快照

### 缓存穿透？

通过bitmap设置布隆过滤器，在缓存前进行拦截过滤（类似于二级缓存）

### 缓存雪崩？

redis缓存的过期时间随机设置

### redis如何解决key冲突？

1. key设计（业务+系统名+关键词）
1. 业务隔离
1. 采用不同的集群
1. 单机系统，可以采用不同的数据库(select)

## kafka

### kafka名词解释

1. Group: 若干个消费者组成一个分组，一个topic可以有多个分组。topic分组内，每一个分区只能有一个消费。如果需要实现广播，只要每个消费者有一个独立的分组即可实现
1. Topic: 主题，队列
1. Partition: 一个topic可以分为多个partition， 每个`partition`是顺序的，但是kafka只保证同一个partition的消息顺序，不保证一个topic的整体顺序。因此如果想要保证顺序只能设置一个partition
1. OFFSET: 偏移量
1. Zookeeper

### kafka消息丢失场景及解决方案？

#### 消息发送

1. 设置ack=0，生产者发送消息，不确认消息是否发送成功，消费发生失败则消息丢失
2. 设置ack=1，生产者发送消息，只确认leader节点发生成功。leader未同步到follwer节点时，leader故障则消失丢失
3. unclean.leader.election.enable设置为true(默认false),允许选举ISR列表以外的副本为leader,

解决方案：ack=all/-1/2/3等多个从节点 ,unclean.leader.election.enable=false

#### 消费者

先commit后处理消息。如果消息处理异常，但是offset已经提交，这条消息对于消费者来说已丢失了

解决方案：先进行消息处理，后进行commit。同时做好业务处理的幂等性



### kafka有哪些特性/kafka为什么快？


### kafka使用哪些场景/为什么要使用kafka？

1. 应用解耦
1. 日志收集
1. 流量削峰

### kafka存储是如何实现的？

### kafka的分区如何使用？

### kafka如何保证消息顺序

1. 只有一个生产者(保证生产者线程安全)
1. kafka的topic必须设置一个分区（保证kafka内部消息发送接收顺序）
1. 只有一个消费者（保证消费者接收消息顺序）

### kafka为什么那么快？

1. 文件顺序读取
1. 写书数据采用0COPY（发送文件描述符）
1.

### kafka有哪些参数?（答出5-10个）

回答该问题主要分四个方面：`系统配置`，`主题参数`，`生产者参数`，`消费者参数`。

1. 系统配置参数

* broker.id

在集群下的唯一id,要求是整数。如果服务器ip发生变化，而broker.id没有变化，则不影响consumers消费情况

* listeners

监听列表，逗号分割，如果hostname为`0.0.0.0`则绑定所有的网卡地址，如果为空，则绑定默认网卡

* zookeeper.connect

zookeeper集群地址，多个采用逗号分隔

* auto.create.topics.enable=true

是否运行自动创建主题，如果设置为true, 那么product,consumer,fetach一个不存在的主题时，会自动创建。一般处于安全考虑会设置为false

1. 主题配置

* num.partitions

新建主题的分区个数。该参数根据消费者处理能力和数量进行确定，分区数应大于消费者数量（1，便于后面扩充消费者数量，2，每一个分区至少一个消费者，分区数大于消费者数量时，消费者会平分分区[分区策略]([https://iscod.github.io/#/amqp/kafka?id=partition]))

* message.max.bytes

消息最大字节数，生产者消费者应该设置一致。该值一般与`fetch.message.max.bytes`配合设置。

1. 生产者配置

* request.timeout.ms

生产者请求的确认超时时间

1. 消费者配置

* enable.auto.commit

是否默认提交，即消费者受到消息后是否会后台自动提交`offsets`，默认是true

* auto.commit.interval.ms

使用者偏移量的提交频率

## RocketMQ

### RocketMQ 的持久化机制？

### RocketMQ 怎么实现消息顺序？

### RocketMQ 事务消息原理？

## mysql

### mysql有哪些存储引擎

`InnoDB`, `MyISAM`, `CSV`等

关键核心：MyISAM不支持事务，InnoDB支持事务。MyISAM支持表锁，InnoDB支持表和行锁。 InnoDB是`MySQL5.1`版本后的默认存储引擎

### mysql的索引有哪些？

该问题的核心点是：mysql的索引是存储引擎实现的，不同的存储引擎索引的工作方式不同。也不是所有的存储引擎都支持所有类型的索引

1. unique(唯一索引)
1. index（b+tree）索引
1. 多列/复合索引
1. 全文索引（FULLTEXT）

### explain用过吗？有哪些主要字段

`type`, `key`, `extra`, `rows`

`type` 常见有 const (查询主键索引，属于精确查找), eq_ref (使用了唯一索引，属于精确查找), ref（使用到了非唯一索引）, range（查找某个索引的部分索引，属于范围查询）, index (查找索引树), all (不使用任何索引，全表扫描)

`extra` 常见有 "Using filesort", "Using index", Using where"等提示我们是否使用索引，是否使用了临时表等

### 哪些情况下索引会失效？

1. like通配符，当`%`出现在左侧时索引会失效
1. 联合索引，查询的列不是联合索引的第一列，索引失效
1. 对索引字段进行了函数运算
1. 对索引列运算（如+-*）
1. 在索引字段上使用（!=,<,>,not in）等时也会失效
1. mysql优化器认为全表扫描比使用索引快时，也会失效，例如：in 的范围过多时

### 什么是写失效？

InnoDB的page和操作系统的页大小不一致，InnoDB的页大小是16kb,操作系统是4kb, InnoDB的页写入磁盘时，一个页需要分四次。

如果在存储引擎写入磁盘时，发生了宕机，那么就有可能未全部写入16kb，这种情况叫部分写入失效（partial page write）,可能导致数据丢失。

* InnoDB如何解决写失效？

为了实现写入数据的安全，InnoDB实现了`double write`来保证写入安全，在`Buffer pool`的`page`写入磁盘真正位置之前，会将数据存入`double write`缓冲区。
`double write`再吸入`doubleWrite`的共享表空间和磁盘数据文件（双写）
这样在宕机重启时，如果出现数据损坏，那么在应用 redo log 之前，通过该副本进行还原`page`数据，然后再做 redo log

```bash
mysql> show variables like "%doublewrite%"; # 查询doublewrite是否开启，默认启用双写缓冲区
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| innodb_doublewrite            | ON    |
| innodb_doublewrite_files      | 2     |
+-------------------------------+-------+
```

### 什么是行溢出？

### mysql有哪些日志？

1. 错误日志
2. bin log日志
3. 慢日志
4. 查询日志

```bash
mysql> set global slow_query_log = 1; # 开启慢日志
mysql> set long_query_time = 2; # 时间临界值2s,可以设置为0记录所有查询
mysql> show variables like "slow_query%";
+---------------------+--------------------------------------+
| Variable_name       | Value                                |
+---------------------+--------------------------------------+
| slow_query_log      | ON                                   |
| slow_query_log_file | /var/lib/mysql/d3e3db712483-slow.log |
+---------------------+--------------------------------------+
2 rows in set (0.02 sec)
```

### mysql内存相关参数

#### Buffer pool

一个大的日志缓存区允许大量的事务在提交之前不写入日志到磁盘。通过设置Buffer pool参数大小，可以大量减少磁盘的I/O次数。（一般建议在数据库服务器上，可以将缓冲池大小设置为服务器物理内存的60%~80%）

```bash
mysql> show variables like "%buffer_pool%"; #查看buffer pool大小
mysql> set global innodb_buffer_pool_size = 3221225472; # 调整buffer pool大小
```

* 如何评估`innodb_buffer_pool_size`设置是否合理？

通过分析InnoDB缓冲池的命中率来验证是否合理，一般命中率低于90%时，可考虑适当增加。

`命中率=Innodb_buffer_pool_read_requests/(Innodb_buffer_pool_read_requests+Innodb_buffer_pool_reads)`

```bash
mysql> show status  like "%buffer_pool_read%";# 查询缓存命中与非命中次数
+---------------------------------------+-------------+
| Variable_name                         | Value       |
+---------------------------------------+-------------+
| Innodb_buffer_pool_read_requests      | 32786546234 |
| Innodb_buffer_pool_reads              | 1096914     |
+---------------------------------------+-------------+
```

#### Page参数

```bash
mysql> show status like "%page_size%";# 查询page_size大小，该值只能通过配置更改，且一般不会设置，使用默认16kb
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| Innodb_page_size | 16384 |
+------------------+-------+
mysql> show status like "%pool_page%";# 查询pool_page相关指标
+----------------------------------+---------+
| Variable_name                    | Value   |
+----------------------------------+---------+
| Innodb_buffer_pool_pages_data    | 7143    |
| Innodb_buffer_pool_pages_dirty   | 0       |
| Innodb_buffer_pool_pages_flushed | 3234771 |
| Innodb_buffer_pool_pages_free    | 1024    |
| Innodb_buffer_pool_pages_misc    | 25      |
| Innodb_buffer_pool_pages_total   | 8192    |
+----------------------------------+---------+
```

### mysql的主键与唯一索引有哪些区别

1. 一个表只能有一个主键，而唯一索引可以有多个
1. 主键可以作为外键使用，而唯一索引不行
1. 主键必定是唯一索引，而唯一索引不一定是主键

### mysql慢查询优化？

1. 优先选择优化高并发，因为高并发的SQL带来的问题后果更严重，且仅仅一点的优化整体的性能就会明显提升
1. 明确优化目标（根据业务和当前数据库状态，以优化的结果给用户一个好的体验，而不一定是消耗的资源最少）
1. explain分析sql语句
1. 永远用小的结果集驱动大的结果集（小的数据集驱动大的结果集，减少内层表读取次数）
1. 尽可能的在索引中完成排序
1. 只使用最有效的过滤条件
1. 只获取自己需要的列
1. 尽量避免复杂的join和子查询
1. 合理设计使用索引（唯一性太差的字段不适合创建索引，更新频繁的字段不适合创建索引，不会出现咋where字句中的不适合创建索引）

### 如何进行JOIN优化？

1. 在不影响查询结果的情况下，驱动表尽量选择结果集最小的那张表（减少外层循环次数）
1. 为匹配的条件增加索引（减少内层表循环的次数）
1. 增加 join buffer size的大小（一次缓存的数据越多，内层循环的扫表次数减少）
1. 减少不必要的字段查询（字段越少，join buffer所缓存的数据越多）

### Mysql为什么使用B+Tree?

* B-Tree的特征

1. 调整B-Tree 的阶数（m），可以降低树的高度，降低查询节点次数
1. 数据记录在所以节点，当数据较大时，相同存储空间，节点保存的key值就会变少，导致B树层数变高

B+Tree是在B-Tree的基础上的一种优化，使其更适合索引结构

* B+Tree的特征

1. 非叶子节点只存储键值信息（根节点和支节点只保存索引，这样节点相同大小的情况下可以保存更多的关键字）
1. 所有叶子节点都有一个链指针用于查找上下节点（这样B+Tree的扫表能力更新，只需要扫描叶子节点即可，而B-Trees需要扫描整个树）
1. 数据记录都存放到叶子节点中


## k8s

k8s是google开发的

## 其它

### 幂等有哪些技术方案?

1. 查询请求

查询`select`是天然幂等，在数控不发生变化时，查询总是相同

1. 删除请求

删除操作也是幂等，区别是删除不存在的数据时，返回可能不同，但对业务没有太多影响

1. 唯一索引（数据唯一）

防止新增脏数据，对需要限制的数据设置唯一索引，保证数据中只存在一份，这样即使有多于请求，也能保证数据仅生成一份。

1. token机制（防止页面重复提交）

数据提交前, 先向服务器申请token, token放到Redis，或内存中，并设置有效期。
客户端拿到token, 提交请求，后台校验token, 同时删除token, 生产新的token返回客户端, 以供下次访问提交

token的特点：需要申请，一次有效性，可以限流

> Redis根据删除操作命令是否返回成功，验证token是否存在

1. traceId(操作标识)

根据用户的动作标识+设备ID+时间等 生产一个`traceId`, 用户提交后，后台判断`traceId`是否已处理，进而判断否是是重复提交

* 参考
* [mysql索引](https://cloud.tencent.com/developer/article/1785124)





