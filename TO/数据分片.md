# 数据分片

## OLTP和OLAP

当应用积累到海量数据时，数据的存储和访问将成为系统设计的与使用的瓶颈问题，对于海量数据处理，按使用场景分为：`OLTP(联机事务处理)`和`OLAP(联机分析处理)`

`OLTP(联机事务处理)`也称为`面向交易的处理系统`,其基本特征是原始数据可以立即传入计算中心进行处理，并在很短的时间内给出处理结果

`OLAP(联机分析处理)`是通过多维的方式对数据进行分析,查询和报表。可以同时对数据挖掘工具，统计分析共计配合使用，增强决策分析功能

OLTP和OLAP主要区分:

 | |OLTP| OLAP
------------- | -------- | -------------------------------
系统功能|日常交易|统计分析,报表|
DB设计|面向实时交易|面向统计分析应用|
数据处理|最新的,细节要求高|历史的,聚集的,统一的|
实时性|实时读写要求高|实时读写要求低|
事务|强一致性|弱事务|
分析要求|低,简单|高,复杂|

## 何为数据切分

通俗来说，数据切分是指通过某种特定的条件，将我们存放在同一数据库中的数据分散存放到多个数据库(主机)上面，已达到分散单台设备负载的效果

数据切分根据其切分的规则类型，可以分为两种切分模式。

一种是按不同的表(或者schema)来切分到不同的数据库(主机)之上，这种称为数据的`垂直(纵向)切分`；

另外一种则是根据表中的数据逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库(主机)之上，这种称为数据的`水平(横向)切分`

`垂直切分`的特点是规则简单，实施方便，适合各业务之间耦合度非常低，相互影响小，业务逻辑非常清晰的系统。
这种系统很容易做到将不同业务模块所使用的表拆分到不同的数据库中

`水平切分`相对于`垂直切分`来说稍微复杂一些，因为要将一个表中的不同数据拆分到不同的数据库中，对于应用程序来说，拆分规则本身就较`垂直切分`复杂，后期的数据维护也更复杂一些。

## 垂直分片

一个数据库由多个表构成，每个表对应不同的业务，垂直切分是按照业务将表进行分类，分布到不同的数据库(或节点)上面。这样也就将数据既压力分担到不同的库上面

垂直分片往往需要对架构和设计进行调整。通常来讲，是来不及应对互联网业务需求快速变化的；而且，它也并无法真正的解决单点瓶颈。 垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。

优点:

    * 拆分开后业务清晰，拆分规则明确
    * 系统之间整合和扩展容易
    * 数据维护简单 

缺点:
    
    * 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度
    * 受业务不同的限制存在单库性能瓶颈，数据不易扩展和进行性能提升
    * 事务处理复杂

`垂直切分`是按业务的分类将表分散到不同的库中，所以有些业务表会过于庞大，存在单库的读写与存储瓶颈，可以通过`水平拆分`解决

## 水平分片

`水平切分`不是将表做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中包含一部分数据。

简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中的某些行切分到一个数据库，而另外的某些行切分到其它数据库中

水平分片从理论上突破的单机数据量处理的瓶颈，并且扩展相对自由，是分库分表的标准解决方案

#### 拆分规则

关系型数据库是行列的二维模型，拆分的第一原则是找到拆分维度。
比如：从用户的角度分析，商户订单交易系统中查询用户某天某月某个订单，那么需要按用户和订单日期拆分，
不同的数据按照用户ID做分组，这样所有的数据查询join都会在单库内解决。
如果从商户的角度来讲，要查询某个商家某天的所有订单数，就需要按照商户ID做拆分。
如果系统想按用户拆分，有想按商家数据拆分就会有一些困难。所以找到合适的分片规则就相当重要

几种典型的分片规则如下：

    * 按用户ID求模，将数据分散到不同的数据库，具有相同数据用户的数据会被分散到同一个库中
    * 按日期分片，将不同月甚至不同日的数据分散到不同的库中
    * 按某个特点的字段求模，或根据特定范围段分散到不同的库中

优点:
    
    * 拆分规则抽象好，join操作基本可以数据库做
    * 不存在单库大数据，高平发性能瓶颈
    * 应用端改动少
    * 提高了系统的稳定性和负载能力

缺点:

    * 拆分规则难以抽象
    * 分片事务一致性难以解决
    * 数据多次扩展难度大
    * 跨库join性能较差

`水平切分`的一些经验:

    * 能不切分尽量不要切分
    * 如果要切分一定要选择合适的切分规则，提前规划
    * 数据切分进行通过数据冗余或表分组来降低跨库join的可能
    * 由于数据库中间件对数据join的实现优劣难以把握，而且实现高性能难度极大，业务读取尽量少使用多表join

## 多数据源管理问题

`垂直切分`和`水平切分`各自都有一些优点和缺点，但是它们有一些共同的缺点:

    * 引入分布式的问题
    * 跨节点Join的问题
    * 跨节点合并排序分页问题
    * 多数据源管理问题

针对数据源管理目前有两种思路
    
    1，客户端模式，在每个应用程序模块中配置管理自己需要的一个（或多个）数据源，直接访问各个数据库，在模块内完成数据的整合
    2，通过中间代理层来统一管理所有的数据源，后端数据库集群对前端应用透明，例如 `mycat`

## 订单ID

订单ID生成的一种典型方式是使用时间戳加上一个随机数

典型订单ID结构

时间戳     | 随机数字
--------- | ------
time      | rand

```php
<?php
function getPayNo()
{
	return date('YmdHis') . rand(1000, 9999);
}
```

这样的结构有一个致命弱点, 即不能100%确保订单ID的唯一性. 虽然看起来在每秒小数据量的情况下可行, 但是在处理大数据量的情况下, 唯一性更难保证, 虽然增加rand的集合看起来可以解决大量订单的情况, 但是还是无法从根本上解决随机数重复出现问题

?> 经过测试悲观情况下上述随机数集在每秒二十次的请求时就会产生重复数据, 所以不要轻易相信这种订单结构生成方式

另一种方式是使用数据库的自增Id来保证唯一性, 虽然可以解决上面随机数的重复性问题, 但是在订单量达到每秒万级别的时候, 数据库性能很难满足, 并且当面临分布式数据架构时数据一致性问题也很难处理, 所以使用数据库自增ID并不会是最好的选择

还有一种方式就是时间戳接合内存 (Redis) 的自增序号获取唯一的订单ID

采用时间戳和内存自增序号订单ID结构:

时间戳     | 机器编号 | 自增序号
--------- | ------- | ------
time      | 1       | incr

- 时间戳 (精确到秒)
- 机器编号 (每个数据服务器都设置一个唯一编号)
- 自增序列 (当在同一时间同一台服务器有多个订单时, 在当前时间戳下自增此序号, 下一秒序号继续从1开始)

```php
<?php
function getPayNo($server_id)
{
	$time = date('YmdHis');
	$incr = $redis->incr($time);
	return $time . $server_id . $incr;
}
```


### 最终一致性


## 数据库高可用

所谓的数据库高可用指的是: 当数据库由于各种原因出现问题时, 能实时或者快速的恢复数据库服务并修补数据, 从整个集群的角度看, 就想没有出现任何问题一样

?> 恢复数据不一定是修复原有数据库, 也可以是切换到其它备库

数据库高可用的主要工作是数据库恢复与数据修补, 一般以完成这两项工作的时间长短来衡量高可用的好坏

?> 数据库恢复的时间越长, 不一致数据会越多, 数据修补的时间就会越长, 整体的修复时间也会变长, 这是一个恶性循环, 所以快速修复数据是数据库高可用中的重点

**经典主从同步结构:**

![经典主从结构](https://iscod.github.io/images/mysql_master_slave_1.png)

经典结构的一大弊病是, 不管主库还是从库一但出现问题, 都需要web应用系统配合完成数据恢复工作, 自动化困难, 恢复过程相当缓慢


**主从高可用结构:**

![主从高可用结构](https://iscod.github.io/images/mysql_master_slave_2.png)


web应用不与Master和Slave库直接连接, 而是连接KeepLive虚拟出的IP和Lvs, KeepLive将此虚拟IP映射到主库Master上, 主库Master有一个备用Master从库, 实时同步数据. 正常服务时web在Master读写数据, 当Master宕机时, 虚拟IP自动映射到Master从库, 这样只需要几秒, 就能完成数据恢复





### 数据分级


### 粗细管道